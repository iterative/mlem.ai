# MLEM Documentation

**MLEM** is a tool to easily package, deploy and serve Machine Learning models.
It seamlessly supports a variety of scenarios like real-time serving and batch
processing.

<admon type="tip">

üí° When combined with [GTO](https://github.com/iterative/gto), MLEM allows you
to create a powerful Model Registry out of your Git repository! Such a registry
serves as a centralized place to store and operationalize your models along with
their metadata; manage model life-cycle, versions & releases, and easily
automate tests and deployments using GitOps.

</admon>

<cards>

  <card href="/doc/get-started" heading="Get Started">
    A step-by-step introduction into basic MLEM features
  </card>

  <card href="/doc/user-guide" heading="User Guide">
    Study the detailed inner-workings of MLEM in its user guide.
  </card>

  <card href="/doc/use-cases" heading="Use Cases">
    Non-exhaustive list of scenarios MLEM can help with
  </card>

  <card href="/doc/api-reference" heading="API Reference">
    See all of MLEM's commands.
  </card>

</cards>

‚úÖ Please join our [community](/community) or use the [support](/support)
channels if you have any questions or need specific help. We are very responsive
‚ö°.

‚úÖ Check out our [GitHub repository](https://github.com/iterative/mlem) and give
us a ‚≠ê if you like the project!

‚úÖ Contribute to MLEM [on GitHub](https://github.com/iterative/mlem) or help us
improve this [documentation](https://github.com/iterative/mlem.ai) üôè.
