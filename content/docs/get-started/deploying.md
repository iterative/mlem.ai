# Deploying models

You can create deployments in the cloud from your models. This uses building
and serving functions under the hood. For example, Heroku deployment combines
Docker image building with FastAPI serving.

<admon type="warn">

This functionality is experimental and is subject to change.

</admon>

## Defining target environment

To deploy something somewhere, we need to define this â€œsomewhereâ€ first, or in
MLEM terms, declare a `target environment` object. It will contain all the
information needed to access it. In the case of Heroku, all we need is an API
key.

<details>

### âš™ï¸How to obtain Heroku API key

- Go to [heroku.com](http://heroku.com)
- Sign up or login with existing account
- Go to account settings by clicking your profile picture on the main page
- Find API Key section and reveal existing one or re-generate it

</details>

To declare a new target env, run

```cli
$ mlem declare env heroku staging -c api_key=<you api key>
ğŸ’¾ Saving env to .mlem/env/staging.mlem
```

<admon type="tip">

MLEM will attempt to use the `HEROKU_API_KEY` environment variable if no
`api_key` argument is provided.

</admon>

## Defining deployment

Now, as we defined our target env, we can deploy our model there. Deployments
are also MLEM objects, which means that they need to have their definition.

To create one for Heroku, we once again will use `declare` command to configure
our deployment. We use `example-mlem-get-started` for the app name, but you can
change it to something unique:

```cli
$ mlem declare deployment heroku myservice \
                         -c app_name=example-mlem-get-started \
                         -c model=rf \
                         -c env=staging
ğŸ’¾ Saving deployment to .mlem/deployment/service_name.mlem
```

<details>

### â›³ [Create deployment definition](https://github.com/iterative/example-mlem-get-started/tree/5-deploy-meta)

```cli
$ git add .mlem/env/staging.mlem .mlem/deployment/myservice.mlem
$ git commit -m "Add env and deploy meta"
$ git diff 5-deploy-meta
```

</details>

Now we can actually run the deployment process (this can take a while):

```cli
$ mlem deployment run myservice
â³ï¸ Loading deployment from .mlem/deployment/myservice.mlem
ğŸ”— Loading link to .mlem/env/staging.mlem
ğŸ”— Loading link to .mlem/model/rf.mlem
ğŸ’¾ Updating deployment at .mlem/deployment/myservice.mlem
ğŸ› Creating Heroku App example-mlem-get-started
ğŸ’¾ Updating deployment at .mlem/deployment/myservice.mlem
ğŸ›  Creating docker image for heroku
  ğŸ’¼ Adding model files...
  ğŸ›  Generating dockerfile...
  ğŸ’¼ Adding sources...
  ğŸ’¼ Generating requirements file...
  ğŸ›  Building docker image registry.heroku.com/example-mlem-get-started/web...
  âœ…  Built docker image registry.heroku.com/example-mlem-get-started/web
  ğŸ”¼ Pushed image registry.heroku.com/example-mlem-get-started/web to remote registry at host registry.heroku.com
ğŸ’¾ Updating deployment at .mlem/deployment/myservice.mlem
ğŸ›  Releasing app my-mlem-service formation
ğŸ’¾ Updating deployment at .mlem/deployment/myservice.mlem
âœ…  Service example-mlem-get-started is up. You can check it out at https://my-mlem-service.herokuapp.com/
```

<admon type="tip">

You can also define and run the deployment on-the-fly using `-c` options for
`mlem deployment run`, e.g.:

```cli
$ mlem deployment run myservice \
                     -m model -t staging \
                     -c app_name=example-mlem-get-started
```

</admon>

<details>

### â›³ [Service deployed](https://github.com/iterative/example-mlem-get-started/tree/8-deploy-create)

```cli
$ git add .mlem/deployment/myservice.mlem
$ git commit -m "Deploy service"
$ git diff 8-deploy-service
```

</details>

## Making requests

You can go [here](http://example-mlem-get-started.herokuapp.com) and see the
same OpenAPI documentation. For details on it, refer to the **Serving** section.
You can also try to do some requests:

```py
from mlem.api import load
from mlem.runtime.client.base import HTTPClient

client = HTTPClient(host="http://example-mlem-get-started.herokuapp.com", port=80)
res = client.predict(load("test_x.csv"))
```

Also, you can create a client using deployment meta object:

```py
from mlem.api import load

service = load("myservice")
client = service.state.get_client()
res = client.predict(load("test_x.csv"))
```

There is also the remote counterpart of `apply` command. It will send requests
to your service instead of loading model into memory. There are two options to
achieve this in CLI: using the service address or the deploy meta.

```cli
$ mlem apply-remote http test_x.csv -c host=http://my-mlem-service.herokuapp.com -c port=80 --json
[1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0]

$ mlem deployment apply myservice test_x.csv --json
[1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0]
```

<admon type="tip">

You donâ€™t even need to have the deployment metadata locally:

```cli
$ mlem deployment apply --json \
  https://github.com/iterative/example-mlem-get-started/myservice \
  https://github.com/iterative/example-mlem-get-started/test_x.csv
```

</admon>

## Managing deployment

Finally, you can check the status of your service with:

```cli
$ mlem deployment status myservice
running
```

And stop your service with

```cli
$ mlem deployment remove myservice
â³ï¸ Loading deployment from .mlem/deployment/myservice.mlem
ğŸ”— Loading link to .mlem/env/staging.mlem
ğŸ”» Deleting my-mlem-service heroku app
ğŸ’¾ Updating deployment at .mlem/deployment/myservice.mlem
```

Note, that it will not delete the deployment definition, just update its state.
